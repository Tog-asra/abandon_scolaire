import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import os
import joblib
from ml_models import StudentAnalysisML
from data_generator import generate_student_data
from fpdf import FPDF
import tempfile
import os


# Configuration de la page
st.set_page_config(
    page_title="Pr√©vention Abandon Scolaire",
    page_icon="üéì",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Style CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #3A7CA5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 5px solid #1f77b4;
    }
    .risk-high {
        background-color: #ffebee;
        border-left-color: #f44336;
    }
    .risk-medium {
        background-color: #fff3e0;
        border-left-color: #ff9800;
    }
    .risk-low {
        background-color: #e8f5e8;
        border-left-color: #4caf50;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_data():
    """Charge les donn√©es avec mise en cache"""
    if not os.path.exists('student_data.csv'):
        df = generate_student_data(1000)
        df.to_csv('student_data.csv', index=False)
    return pd.read_csv('student_data.csv')

@st.cache_resource
def load_ml_models():
    """Charge les mod√®les ML avec mise en cache"""
    ml_analyzer = StudentAnalysisML()
    
    if os.path.exists('models/models.pkl'):
        try:
            # Charger les mod√®les existants
            ml_analyzer.models = joblib.load('models/models.pkl')
            ml_analyzer.scaler = joblib.load('models/scaler.pkl')
            ml_analyzer.label_encoders = joblib.load('models/label_encoders.pkl')
            ml_analyzer.feature_selector = joblib.load('models/feature_selector.pkl')
            ml_analyzer.selected_features = joblib.load('models/selected_features.pkl')
            
            # Charger et pr√©processer les donn√©es
            ml_analyzer.load_and_preprocess_data('student_data.csv')
            
            print("‚úÖ Mod√®les charg√©s avec succ√®s")
            
        except Exception as e:
            st.error(f"Erreur lors du chargement des mod√®les: {e}")
            # Fallback: entra√Æner les mod√®les
            ml_analyzer.load_and_preprocess_data('student_data.csv')
            ml_analyzer.train_classification_models()
            perform_clustering_safe(ml_analyzer)
            ml_analyzer.save_models()
    else:
        # Entra√Æner les mod√®les
        try:
            ml_analyzer.load_and_preprocess_data('student_data.csv')
            ml_analyzer.train_classification_models()
            perform_clustering_safe(ml_analyzer)
            ml_analyzer.save_models()
            print("‚úÖ Mod√®les entra√Æn√©s et sauvegard√©s")
        except Exception as e:
            st.error(f"Erreur lors de l'entra√Ænement des mod√®les: {e}")
    
    return ml_analyzer

def perform_clustering_safe(ml_analyzer):
    """Effectue le clustering de mani√®re s√©curis√©e"""
    try:
        if ml_analyzer.X_scaled is not None and hasattr(ml_analyzer, 'df') and ml_analyzer.df is not None:
            ml_analyzer.perform_clustering()
        else:
            st.warning("Clustering non disponible - donn√©es non pr√©par√©es correctement")
    except Exception as e:
        st.warning(f"Clustering non effectu√©: {e}")

def create_pdf_report(student_data, prediction, recommendations):
    """Cr√©e un rapport PDF"""
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font('Arial', 'B', 16)
    
    # Titre
    pdf.cell(0, 10, 'Rapport de Risque d\'Abandon Scolaire', 0, 1, 'C')
    pdf.ln(10)
    
    # Informations de l'√©tudiant
    pdf.set_font('Arial', 'B', 12)
    pdf.cell(0, 10, 'Informations de l\'etudiant:', 0, 1)
    pdf.set_font('Arial', '', 10)
    
    for key, value in student_data.items():
        pdf.cell(0, 8, f'{key}: {value}', 0, 1)
    
    pdf.ln(5)
    
    # Pr√©diction
    pdf.set_font('Arial', 'B', 12)
    pdf.cell(0, 10, 'Evaluation du risque:', 0, 1)
    pdf.set_font('Arial', '', 10)
    pdf.cell(0, 8, f'Probabilite d\'abandon: {prediction["risk_probability"]:.1%}', 0, 1)
    pdf.cell(0, 8, f'Niveau de risque: {prediction["risk_level"]}', 0, 1)
    
    pdf.ln(5)
    
    # Recommandations
    pdf.set_font('Arial', 'B', 12)
    pdf.cell(0, 10, 'Recommandations:', 0, 1)
    pdf.set_font('Arial', '', 10)
    
    for rec in recommendations:
        pdf.cell(0, 8, f'- {rec}', 0, 1)
    
    return pdf

def generate_recommendations(student_data, prediction):
    """G√©n√®re des recommandations personnalis√©es"""
    recommendations = []
    
    if prediction['risk_probability'] > 0.7:
        recommendations.append("Suivi personnalis√© urgent recommand√©")
        recommendations.append("Rencontre avec le conseiller p√©dagogique")
    
    if student_data['note_moyenne'] < 10:
        recommendations.append("Mise en place d'un tutorat acad√©mique")
        recommendations.append("R√©vision des m√©thodes d'apprentissage")
    
    if student_data['taux_absenteisme'] > 25:
        recommendations.append("Suivi de l'assiduit√© renforc√©")
        recommendations.append("Identification des causes d'absent√©isme")
    
    if student_data['satisfaction_etudiant'] < 6:
        recommendations.append("Enqu√™te de satisfaction approfondie")
        recommendations.append("Am√©lioration de l'exp√©rience √©tudiante")
    
    if student_data['temps_moodle_heures'] < 30:
        recommendations.append("Encourager l'utilisation des ressources num√©riques")
        recommendations.append("Formation aux outils p√©dagogiques en ligne")
    
    if student_data['participation_forums'] < 3:
        recommendations.append("Encourager la participation aux forums")
        recommendations.append("Activit√©s collaboratives en ligne")
    
    if not recommendations:
        recommendations.append("Continuer le suivi r√©gulier")
        recommendations.append("Maintenir l'engagement actuel")
    
    return recommendations

# Interface principale
def main():
    st.markdown('<h1 class="main-header">üéì Pr√©vention de l\'Abandon Scolaire</h1>', unsafe_allow_html=True)
    
    # Chargement des donn√©es et mod√®les
    try:
        df = load_data()
        ml_analyzer = load_ml_models()
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es/mod√®les: {e}")
        st.stop()
    
    # Sidebar pour navigation
    st.sidebar.title("Navigation")
    page = st.sidebar.selectbox(
        "Choisir une page:",
        ["Dashboard Exploratoire", "Analyse des Clusters", "Simulation Individuelle", "R√®gles d'Association"]
    )
    
    if page == "Dashboard Exploratoire":
        st.header("üìä Analyse Exploratoire des Donn√©es")
        
        # M√©triques globales
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Nombre d'√©tudiants", len(df))
        
        with col2:
            abandon_rate = df['abandon'].mean()
            st.metric("Taux d'abandon", f"{abandon_rate:.1%}")
        
        with col3:
            avg_grade = df['note_moyenne'].mean()
            st.metric("Note moyenne", f"{avg_grade:.1f}/20")
        
        with col4:
            avg_satisfaction = df['satisfaction_etudiant'].mean()
            st.metric("Satisfaction moyenne", f"{avg_satisfaction:.1f}/10")
        
        # Visualisations
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Distribution des abandons par r√©gion")
            fig_region = px.histogram(df, x='region', color='abandon', 
                                    title='Abandons par r√©gion',
                                    color_discrete_map={0: 'lightblue', 1: 'red'})
            st.plotly_chart(fig_region, use_container_width=True)
        
        with col2:
            st.subheader("Corr√©lation entre variables")
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            corr_matrix = df[numeric_cols].corr()
            
            fig_corr = px.imshow(corr_matrix, 
                               title='Matrice de corr√©lation',
                               color_continuous_scale='RdBu')
            st.plotly_chart(fig_corr, use_container_width=True)
        
        # Analyse des notes vs abandon
        st.subheader("Analyse des facteurs de risque")
        
        col1, col2 = st.columns(2)
        
        with col1:
            fig_notes = px.box(df, x='abandon', y='note_moyenne',
                             title='Distribution des notes par statut d\'abandon')
            st.plotly_chart(fig_notes, use_container_width=True)
        
        with col2:
            fig_absent = px.box(df, x='abandon', y='taux_absenteisme',
                              title='Absent√©isme par statut d\'abandon')
            st.plotly_chart(fig_absent, use_container_width=True)
        
        # Importance des features
        if hasattr(ml_analyzer, 'models') and 'random_forest' in ml_analyzer.models:
            st.subheader("Importance des caract√©ristiques")
            try:
                feature_importance = ml_analyzer.get_feature_importance()
                if feature_importance is not None:
                    fig_importance = px.bar(feature_importance, 
                                          x='importance', 
                                          y='feature',
                                          orientation='h',
                                          title='Importance des variables pour pr√©dire l\'abandon')
                    st.plotly_chart(fig_importance, use_container_width=True)
            except Exception as e:
                st.warning(f"Impossible d'afficher l'importance des features: {e}")
    
    elif page == "Analyse des Clusters":
        st.header("üéØ Segmentation des √âtudiants")
        
        # V√©rifier si le clustering a √©t√© effectu√©
        if 'cluster_kmeans' not in df.columns and hasattr(ml_analyzer, 'df') and ml_analyzer.df is not None:
            with st.spinner("Effectuation du clustering..."):
                perform_clustering_safe(ml_analyzer)
                if hasattr(ml_analyzer, 'df') and 'cluster_kmeans' in ml_analyzer.df.columns:
                    df = ml_analyzer.df
        
        if 'cluster_kmeans' in df.columns:
            # Visualisation des clusters
            st.subheader("Profils d'√©tudiants identifi√©s")
            
            # R√©duction de dimensionnalit√© pour visualisation
            try:
                from sklearn.decomposition import PCA
                
                # Pr√©paration des donn√©es pour PCA
                numeric_cols = ['age', 'note_moyenne', 'taux_absenteisme', 'taux_remise_devoirs', 
                               'temps_moodle_heures', 'participation_forums', 'satisfaction_etudiant']
                X_pca = df[numeric_cols].fillna(df[numeric_cols].mean())
                
                pca = PCA(n_components=2)
                X_pca_transformed = pca.fit_transform(X_pca)
                
                df_pca = pd.DataFrame({
                    'PC1': X_pca_transformed[:, 0],
                    'PC2': X_pca_transformed[:, 1],
                    'Cluster': df['cluster_kmeans'].astype(str),
                    'Abandon': df['abandon'].astype(str)
                })
                
                fig_clusters = px.scatter(df_pca, x='PC1', y='PC2', 
                                        color='Cluster',
                                        symbol='Abandon',
                                        title='Visualisation des clusters d\'√©tudiants',
                                        labels={'PC1': 'Premi√®re composante principale',
                                               'PC2': 'Deuxi√®me composante principale'})
                st.plotly_chart(fig_clusters, use_container_width=True)
                
                # Analyse des profils par cluster
                st.subheader("Caract√©ristiques par cluster")
                
                cluster_stats = df.groupby('cluster_kmeans').agg({
                    'abandon': 'mean',
                    'note_moyenne': 'mean',
                    'taux_absenteisme': 'mean',
                    'satisfaction_etudiant': 'mean',
                    'temps_moodle_heures': 'mean'
                }).round(2)
                
                cluster_stats.columns = ['Taux abandon', 'Note moyenne', 'Absent√©isme (%)', 
                                       'Satisfaction', 'Temps Moodle (h)']
                
                st.dataframe(cluster_stats, use_container_width=True)
                
                # Description des profils
                st.subheader("Interpr√©tation des profils")
                
                for cluster_id in sorted(df['cluster_kmeans'].unique()):
                    cluster_data = df[df['cluster_kmeans'] == cluster_id]
                    abandon_rate = cluster_data['abandon'].mean()
                    
                    if abandon_rate > 0.5:
                        risk_level = "üî¥ Tr√®s haut risque"
                        color = "risk-high"
                    elif abandon_rate > 0.3:
                        risk_level = "üü° Risque mod√©r√©"
                        color = "risk-medium"
                    else:
                        risk_level = "üü¢ Faible risque"
                        color = "risk-low"
                    
                    st.markdown(f"""
                    <div class="metric-card {color}">
                        <h4>Cluster {cluster_id} - {risk_level}</h4>
                        <p><strong>Taille:</strong> {len(cluster_data)} √©tudiants ({len(cluster_data)/len(df)*100:.1f}%)</p>
                        <p><strong>Taux d'abandon:</strong> {abandon_rate:.1%}</p>
                        <p><strong>Note moyenne:</strong> {cluster_data['note_moyenne'].mean():.1f}/20</p>
                        <p><strong>Absent√©isme:</strong> {cluster_data['taux_absenteisme'].mean():.1f}%</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
            except Exception as e:
                st.error(f"Erreur lors de l'analyse des clusters: {e}")
        else:
            st.warning("Clustering non disponible. Veuillez relancer l'application ou r√©entra√Æner les mod√®les.")
    
    elif page == "Simulation Individuelle":
        st.header("üë§ √âvaluation Individuelle du Risque")
        
        st.markdown("Entrez les informations de l'√©tudiant pour √©valuer son risque d'abandon:")
        
        # Interface de saisie
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Informations personnelles")
            age = st.slider("√Çge", 17, 30, 20)
            sexe = st.selectbox("Sexe", ['M', 'F'])
            region = st.selectbox("R√©gion", ['Urbaine', 'Rurale', 'Semi-urbaine'])
            niveau_parents = st.selectbox("Niveau d'√©ducation des parents", 
                                        ['Primaire', 'Secondaire', 'Universit√©', 'Post-grad'])
            situation_financiere = st.selectbox("Situation financi√®re", 
                                              ['Pr√©caire', 'Moyenne', 'Bonne'])
        
        with col2:
            st.subheader("Performances acad√©miques")
            note_moyenne = st.slider("Note moyenne (/20)", 0.0, 20.0, 12.0, 0.1)
            taux_absenteisme = st.slider("Taux d'absent√©isme (%)", 0, 100, 15)
            taux_remise_devoirs = st.slider("Taux de remise des devoirs (%)", 0, 100, 85)
            temps_moodle = st.slider("Temps sur Moodle (heures/mois)", 0, 200, 50)
            participation_forums = st.slider("Participation aux forums", 0, 20, 5)
            satisfaction = st.slider("Satisfaction (/10)", 1, 10, 7)
        
        # Bouton de pr√©diction
        if st.button("√âvaluer le risque", type="primary"):
            student_data = {
                'age': age,
                'sexe': sexe,
                'region': region,
                'niveau_education_parents': niveau_parents,
                'situation_financiere': situation_financiere,
                'note_moyenne': note_moyenne,
                'taux_absenteisme': taux_absenteisme,
                'taux_remise_devoirs': taux_remise_devoirs,
                'temps_moodle_heures': temps_moodle,
                'participation_forums': participation_forums,
                'satisfaction_etudiant': satisfaction
            }
            
            # Pr√©diction
            try:
                prediction = ml_analyzer.predict_dropout_risk(student_data)
                
                # Affichage du r√©sultat
                st.subheader("R√©sultat de l'√©valuation")
                
                risk_prob = prediction['risk_probability']
                risk_level = prediction['risk_level']
                
                if risk_level == '√âlev√©':
                    color = "risk-high"
                    emoji = "üî¥"
                elif risk_level == 'Moyen':
                    color = "risk-medium"
                    emoji = "üü°"
                else:
                    color = "risk-low"
                    emoji = "üü¢"
                
                st.markdown(f"""
                <div class="metric-card {color}">
                    <h3>{emoji} Niveau de risque: {risk_level}</h3>
                    <h4>Probabilit√© d'abandon: {risk_prob:.1%}</h4>
                </div>
                """, unsafe_allow_html=True)
                
                # D√©tail des pr√©dictions des mod√®les
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Random Forest", f"{prediction['rf_probability']:.1%}")
                with col2:
                    st.metric("XGBoost", f"{prediction['xgb_probability']:.1%}")
                
                # G√©n√©ration des recommandations
                recommendations = generate_recommendations(student_data, prediction)
                
                st.subheader("Recommandations personnalis√©es")
                for i, rec in enumerate(recommendations, 1):
                    st.write(f"{i}. {rec}")
                
                # Cr√©e une variable de session pour stocker le PDF temporairement
                if "pdf_ready" not in st.session_state:
                    st.session_state.pdf_ready = False
                    st.session_state.pdf_path = ""

                # G√©n√©ration du PDF
                if st.button("G√©n√©rer rapport PDF"):
                    try:
                        pdf = create_pdf_report(student_data, prediction, recommendations)

                        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                            pdf.output(tmp_file.name)
                            st.session_state.pdf_path = tmp_file.name
                            st.session_state.pdf_ready = True
                            st.success("‚úÖ Rapport g√©n√©r√© avec succ√®s ! Cliquez ci-dessous pour le t√©l√©charger.")
                    except Exception as e:
                        st.error(f"Erreur lors de la g√©n√©ration du PDF : {e}")
                    st.session_state.pdf_ready = False

                # Bouton de t√©l√©chargement s‚Äôaffiche apr√®s g√©n√©ration
                if st.session_state.pdf_ready:
                    with open(st.session_state.pdf_path, "rb") as f:
                        st.download_button(
                        label="üìÑ T√©l√©charger le rapport PDF",
                        data=f.read(),
                        file_name="rapport_risque_abandon.pdf",
                        mime="application/pdf"
                    )
            except Exception as e:
                st.error(f"Erreur lors de la pr√©diction: {str(e)}")
                st.info("Veuillez v√©rifier que les mod√®les sont correctement entra√Æn√©s.")
    
    elif page == "R√®gles d'Association":
        st.header("üîó R√®gles d'Association")
        
        st.markdown("D√©couverte de sch√©mas comportementaux menant √† l'abandon scolaire")
        
        # G√©n√©ration des r√®gles d'association
        with st.spinner("G√©n√©ration des r√®gles d'association..."):
            try:
                rules = ml_analyzer.generate_association_rules(min_support=0.01, min_confidence=0.4)
                
                if not rules.empty:
                    st.subheader("R√®gles d√©couvertes")
                    
                    # Filtrage interactif
                    min_confidence = st.slider("Confiance minimale", 0.0, 1.0, 0.6, 0.05)
                    min_lift = st.slider("Lift minimal", 1.0, 10.0, 1.2, 0.1)
                    
                    filtered_rules = rules[(rules['confidence'] >= min_confidence) & 
                                         (rules['lift'] >= min_lift)]
                    
                    if not filtered_rules.empty:
                        # Affichage des r√®gles
                        st.write(f"**{len(filtered_rules)} r√®gles trouv√©es**")
                        
                        for idx, rule in filtered_rules.head(10).iterrows():
                            antecedents = ', '.join(list(rule['antecedents']))
                            consequents = ', '.join(list(rule['consequents']))
                            
                            st.markdown(f"""
                            <div class="metric-card">
                                <h4>Si {antecedents}</h4>
                                <h4>Alors {consequents}</h4>
                                <p><strong>Confiance:</strong> {rule['confidence']:.2%} | 
                                   <strong>Support:</strong> {rule['support']:.2%} | 
                                   <strong>Lift:</strong> {rule['lift']:.2f}</p>
                            </div>
                            """, unsafe_allow_html=True)
                        
                        # Visualisation des r√®gles
                        if len(filtered_rules) > 0:
                            st.subheader("Visualisation des r√®gles")
                            
                            fig_rules = px.scatter(filtered_rules, 
                                                 x='support', 
                                                 y='confidence',
                                                 size='lift',
                                                 hover_data=['lift'],
                                                 title='Support vs Confiance des r√®gles')
                            st.plotly_chart(fig_rules, use_container_width=True)
                    else:
                        st.warning("Aucune r√®gle ne correspond aux crit√®res s√©lectionn√©s.")
                else:
                    st.warning("Aucune r√®gle d'association trouv√©e avec les param√®tres actuels.")
                    
            except Exception as e:
                st.error(f"Erreur lors de la g√©n√©ration des r√®gles: {str(e)}")
                st.info("Essayez de r√©duire les seuils de support et de confiance.")
    
    # Footer
    st.markdown("---")
    st.markdown(
        "üéì **Syst√®me de Pr√©vention de l'Abandon Scolaire** | "
        "D√©velopp√© avec Streamlit et Machine Learning"
    )

if __name__ == "__main__":
    main()